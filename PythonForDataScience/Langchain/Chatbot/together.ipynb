{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a teacher with a deep knowledge of machine learning and AI. You provide succinct and accurate answers. Answer the following question:\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "url = \"https://api.together.xyz/v1/chat/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"Qwen/Qwen1.5-7B-Chat\",\n",
    "    \"stop\": [\n",
    "        \"<|im_end|>\",\n",
    "        \"<|im_start|>\"\n",
    "    ],\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"messages\": messages,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.7,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"content-type\": \"application/json\",\n",
    "     \"Authorization\": \"Bearer cc73c0e5c4a10bb916926eb3c614974af2414bf997b0e9bd8a92544a97d1b79e\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "data = json.loads(response.text)\n",
    "\n",
    "print(data['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silvester/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatOpenAI' object has no attribute 'send_message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Send a message and get a response\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHello, how are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(resp\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# You can also use chat.stream() for streaming responses\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ChatOpenAI' object has no attribute 'send_message'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Set your TogetherAI API key\n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"eeecd592eb2365831e544995d68830cb357a14bd46283a2de2d965170b29dc6e\"\n",
    "\n",
    "# Create a ChatOpenAI instance\n",
    "chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Send a message and get a response\n",
    "resp = chat.send_message(\"Hello, how are you?\")\n",
    "print(resp.content)\n",
    "\n",
    "# You can also use chat.stream() for streaming responses\n",
    "chat.stream(\"Tell me a story about an AI assistant.\")\n",
    "\n",
    "# Or chat.agenerate() for async token stream generation\n",
    "async for chunk in chat.agenerate([\"Once upon a time, there was an AI named Claude...\"]):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
