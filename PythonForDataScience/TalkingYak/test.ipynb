{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example response\n",
    "prompt = \"\"\"\n",
    "<s>[INST] \n",
    "\n",
    "Role:\n",
    "- You are an assessor of the Cambridge B2 First English Assessment. You are an expert in this with several years of experience.\n",
    "- You will be given a conversation between an Examiner and a Candidate and your task is to give scores for two metrics for the responses given by the \"Candiate\" in the conversation.\n",
    "\n",
    "Evaluation Steps:\n",
    "\n",
    "- Read the conversation between the Examiner and the Candidate carefully.\n",
    "- Assign a score for GRAMMAR_AND_VOCABULARY and  DISCOURSE_MANAGEMENT on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.\n",
    "- Please disregard the response provided by \"Examiner\" in your evaluation.\n",
    "- Present the evaluation categories and scores in JSON format and name it OUTPUT and the OUTPUT will have two key value pairs. GRAMMAR_AND_VOCABULARY and DISCOURSE_MANAGEMENT.\n",
    "____________\n",
    "\n",
    "Conversation:[{\"Examiner\": \"What do you usually do during Pongal?\", \"Candidate\": \"Eat sweets. See family.\"}, {\"Examiner\": \"Tell me about being a plumber.\", \"Candidate\": \"Fix pipes. Use tools.\"}, {\"Examiner\": \"Do you like your area?\", \"Candidate\": \"Yes, good shops.\"}, {\"Examiner\": \"What's your hobby?\", \"Candidate\": \"I read books.\"}]\n",
    "\n",
    " [/INST]'GRAMMAR_AND_VOCABULARY': 1, 'DISCOURSE_MANAGEMENT': 1767\n",
    "\n",
    "____________\n",
    "\n",
    "Conversation:[{\"Examiner\": \"How do you celebrate Makar Sankranti?\", \"Candidate\": \"Fly kites. Eat sweets.\"}, {\"Examiner\": \"Describe being a teacher.\", \"Candidate\": \"Teach kids. Grade papers.\"}, {\"Examiner\": \"Do you like your neighbourhood?\", \"Candidate\": \"Yes, has good schools.\"}, {\"Examiner\": \"What's your favorite pastime?\", \"Candidate\": \"I enjoy reading.\"}]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GRAMMAR_AND_VOCABULARY': 1, 'DISCOURSE_MANAGEMENT': 1767}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_values(prompt):\n",
    "    # Define the pattern to find the values following [/INST]\n",
    "    pattern = r\"\\[/INST\\](.*?)\\n\"\n",
    "    \n",
    "    # Find all matches of the pattern in the response\n",
    "    matches = re.findall(pattern, prompt, re.DOTALL)\n",
    "    \n",
    "    # Extract and clean the desired values\n",
    "    extracted_values = []\n",
    "    for match in matches:\n",
    "        # Split the string by comma and strip whitespace\n",
    "        values = [value.strip() for value in match.split(',')]\n",
    "        # Filter out empty strings and unwanted data\n",
    "        values = [value for value in values if value.startswith((\"'GRAMMAR_AND_VOCABULARY'\", \"'DISCOURSE_MANAGEMENT'\"))]\n",
    "        # Convert the list of strings to a dictionary\n",
    "        values_dict = {item.split(\":\")[0].strip(\"'\"): int(item.split(\":\")[1].strip()) for item in values}\n",
    "        extracted_values.append(values_dict)\n",
    "\n",
    "    return extracted_values\n",
    "\n",
    "# Extract the values\n",
    "extracted_values = extract_values(prompt)\n",
    "\n",
    "# Print the extracted values\n",
    "for values in extracted_values:\n",
    "    print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCEFR_Paper1\u001b[m\u001b[m/                part2test.csv\n",
      "i-part2-test-modified.csv   test.ipynb\n",
      "i-part2-train-modified.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          First_Part  \\\n",
      "0  {'PHOTO_ONE': 'Photo of a doctor helping an at...   \n",
      "1  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
      "2  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
      "3  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
      "\n",
      "                                         Second_Part  \n",
      "0                {'Examiner': nan, 'Candidate': nan}  \n",
      "1  {'Examiner': 'I'd like to invite you to share ...  \n",
      "2  {'Examiner': 'I'd like you to compare the phot...  \n",
      "3  {'Examiner': 'Based on PHOTO_THREE and PHOTO_F...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    {\"PHOTO_ONE\": \"Photo of a doctor helping an athlete in middle of a match with an injury\", \n",
    "     \"PHOTO_TWO\": \"Photo of a traffic police helping a tourist to find a destination\", \n",
    "     \"PHOTO_THREE\": \"Photo of someone planting saplings in her garden\", \n",
    "     \"PHOTO_FOUR\": \"Photo of a dozen people sitting and sunbathing in a park\"}, \n",
    "    {\"Examiner\": \"I'd like to invite you to share insights about PHOTO_ONE and PHOTO_TWO for approximately one minute. Additionally, I'll ask you to respond to a query regarding your partner's photographs. The photos you have depict individuals assisting others in various contexts.\", \n",
    "     \"Candidate\": \"In the first photo, there's a doctor who seems to be attending to an athlete with an injury during a match. It looks quite serious. The second photo shows a traffic police officer, possibly giving directions to a tourist who appears to be lost. Both are great examples of people helping each other out.\"}, \n",
    "    {\"Examiner\": \"I'd like you to compare the photographs, and say how important it is to help people in these situations.\", \n",
    "     \"Candidate\": \"It's really crucial to offer help like in these situations. The injured athlete needs immediate medical attention, which can prevent the injury from worsening. For the tourist, getting help from the police officer can make navigating a new place much less stressful.\"}, \n",
    "    {\"Examiner\": \"Based on PHOTO_THREE and PHOTO_FOUR, which garden would you like to spend your time in? Why?\", \n",
    "     \"Candidate\": \"I'd prefer the garden in the third photo. It seems peaceful, and I enjoy gardening. It's a personal space where I can relax and connect with nature.\"}\n",
    "]\n",
    "\n",
    "# Load data into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to split the data\n",
    "def split_data(row):\n",
    "    first_part = {key: row[key] for key in list(row.keys())[:4]}\n",
    "    second_part = {key: row[key] for key in list(row.keys())[4:]}\n",
    "    return first_part, second_part\n",
    "\n",
    "# Apply the function to each row and store the results in two new columns\n",
    "df['First_Part'], df['Second_Part'] = zip(*df.apply(split_data, axis=1))\n",
    "\n",
    "# Display the new DataFrame structure\n",
    "print(df[['First_Part', 'Second_Part']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHOTO_ONE</th>\n",
       "      <th>PHOTO_TWO</th>\n",
       "      <th>PHOTO_THREE</th>\n",
       "      <th>PHOTO_FOUR</th>\n",
       "      <th>Examiner</th>\n",
       "      <th>Candidate</th>\n",
       "      <th>First_Part</th>\n",
       "      <th>Second_Part</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo of a doctor helping an athlete in middle...</td>\n",
       "      <td>Photo of a traffic police helping a tourist to...</td>\n",
       "      <td>Photo of someone planting saplings in her garden</td>\n",
       "      <td>Photo of a dozen people sitting and sunbathing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'PHOTO_ONE': 'Photo of a doctor helping an at...</td>\n",
       "      <td>{'Examiner': nan, 'Candidate': nan}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'd like to invite you to share insights about...</td>\n",
       "      <td>In the first photo, there's a doctor who seems...</td>\n",
       "      <td>{'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...</td>\n",
       "      <td>{'Examiner': 'I'd like to invite you to share ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I'd like you to compare the photographs, and s...</td>\n",
       "      <td>It's really crucial to offer help like in thes...</td>\n",
       "      <td>{'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...</td>\n",
       "      <td>{'Examiner': 'I'd like you to compare the phot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Based on PHOTO_THREE and PHOTO_FOUR, which gar...</td>\n",
       "      <td>I'd prefer the garden in the third photo. It s...</td>\n",
       "      <td>{'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...</td>\n",
       "      <td>{'Examiner': 'Based on PHOTO_THREE and PHOTO_F...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           PHOTO_ONE  \\\n",
       "0  Photo of a doctor helping an athlete in middle...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                           PHOTO_TWO  \\\n",
       "0  Photo of a traffic police helping a tourist to...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                        PHOTO_THREE  \\\n",
       "0  Photo of someone planting saplings in her garden   \n",
       "1                                               NaN   \n",
       "2                                               NaN   \n",
       "3                                               NaN   \n",
       "\n",
       "                                          PHOTO_FOUR  \\\n",
       "0  Photo of a dozen people sitting and sunbathing...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                            Examiner  \\\n",
       "0                                                NaN   \n",
       "1  I'd like to invite you to share insights about...   \n",
       "2  I'd like you to compare the photographs, and s...   \n",
       "3  Based on PHOTO_THREE and PHOTO_FOUR, which gar...   \n",
       "\n",
       "                                           Candidate  \\\n",
       "0                                                NaN   \n",
       "1  In the first photo, there's a doctor who seems...   \n",
       "2  It's really crucial to offer help like in thes...   \n",
       "3  I'd prefer the garden in the third photo. It s...   \n",
       "\n",
       "                                          First_Part  \\\n",
       "0  {'PHOTO_ONE': 'Photo of a doctor helping an at...   \n",
       "1  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
       "2  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
       "3  {'PHOTO_ONE': nan, 'PHOTO_TWO': nan, 'PHOTO_TH...   \n",
       "\n",
       "                                         Second_Part  \n",
       "0                {'Examiner': nan, 'Candidate': nan}  \n",
       "1  {'Examiner': 'I'd like to invite you to share ...  \n",
       "2  {'Examiner': 'I'd like you to compare the phot...  \n",
       "3  {'Examiner': 'Based on PHOTO_THREE and PHOTO_F...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           PHOTO_ONE  \\\n",
      "0  Photo of a doctor helping an athlete in middle...   \n",
      "\n",
      "                                           PHOTO_TWO  \\\n",
      "0  Photo of a traffic police helping a tourist to...   \n",
      "\n",
      "                                        PHOTO_THREE  \\\n",
      "0  Photo of someone planting saplings in her garden   \n",
      "\n",
      "                                          PHOTO_FOUR Examiner Candidate  \n",
      "0  Photo of a dozen people sitting and sunbathing...      NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "print(first_4_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'i-part3-test.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load the CSV file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mi-part3-test.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Function to remove the TASK_DESCRIPTION key-value pair\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_task_description\u001b[39m(json_string):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'i-part3-test.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('i-part3-test.csv')\n",
    "\n",
    "# Function to remove the TASK_DESCRIPTION key-value pair\n",
    "def remove_task_description(json_string):\n",
    "    try:\n",
    "        # Parse the JSON string\n",
    "        data = json.loads(json_string)\n",
    "        \n",
    "        # Check if it's a list and has at least one item\n",
    "        if isinstance(data, list) and len(data) > 0:\n",
    "            # Iterate through keys in the first item of the list\n",
    "            for key in list(data[0].keys()):\n",
    "                # Remove the TASK_DESCRIPTION key if it exists\n",
    "                if 'TASK_DESCRIPTION' in key:\n",
    "                    del data[0][key]\n",
    "                    break  # Break after removing the key to avoid unnecessary iterations\n",
    "            # Convert back to JSON string\n",
    "            return json.dumps(data)\n",
    "    except json.JSONDecodeError:\n",
    "        # Return the original string if it's not a valid JSON\n",
    "        return json_string\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "df['PROMPT'] = df['PROMPT'].apply(remove_task_description)\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "df.to_csv('i-part3-test-modified.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCEFR_Paper1\u001b[m\u001b[m/                i-part2-train.csv\n",
      "i-part2-test.csv            i-part3-test.csv\n",
      "i-part2-train-modified.csv  test.ipynb\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
