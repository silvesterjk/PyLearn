{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Classes and Objects: Meet the Heroes\n",
    "\n",
    "#### 2.1 Defining a Class: The Blueprint of a Hero\n",
    "A class is like a blueprint that defines the structure and behavior of an object. Let's create a generic Hero class that will serve as the base for our specialized heroes like archers and wizards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero:\n",
    "    def __init__(self, name, level):\n",
    "        self.name = name\n",
    "        self.level = level\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Hero\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Creating Objects: Summoning Heroes\n",
    "An object is an instance of a class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      "Max, Level 5 Hero\n"
     ]
    }
   ],
   "source": [
    "hero = Hero(\"Max\", 5)\n",
    "print(hero.name)\n",
    "print(hero.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dive deeper into the internals of classes and instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero:\n",
    "    weight = 100\n",
    "\n",
    "    def __init__(self, name, level):\n",
    "        self.name = name\n",
    "        self.level = level\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Hero\"\n",
    "\n",
    "\n",
    "hero1 = Hero(\"Merlin\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'weight': 100,\n",
       "              '__init__': <function __main__.Hero.__init__(self, name, level)>,\n",
       "              'describe': <function __main__.Hero.describe(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'Hero' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Hero' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hero.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Merlin', 'level': 10}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(hero1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': '__main__',\n",
       "              'weight': 100,\n",
       "              '__init__': <function __main__.Hero.__init__(self, name, level)>,\n",
       "              'describe': <function __main__.Hero.describe(self)>,\n",
       "              '__dict__': <attribute '__dict__' of 'Hero' objects>,\n",
       "              '__weakref__': <attribute '__weakref__' of 'Hero' objects>,\n",
       "              '__doc__': None})"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero1.__class__.__dict__  # Just for demonstration, never use code like this ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inheritance\n",
    "Inheritance allows a class to inherit attributes and methods from another class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robin, Level 10 Archer\n",
      "Merlin, Level 12 Wizard\n"
     ]
    }
   ],
   "source": [
    "class Archer(Hero):\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Archer\"\n",
    "\n",
    "\n",
    "class Wizard(Hero):\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Wizard\"\n",
    "\n",
    "\n",
    "archer = Archer(\"Robin\", 10)\n",
    "wizard = Wizard(\"Merlin\", 12)\n",
    "\n",
    "print(archer.describe())\n",
    "print(wizard.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `super()` to call methods of the parent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Archer(Hero):\n",
    "    def __init__(self, name, level, arrow_count):\n",
    "        super().__init__(name, level)\n",
    "        self.arrow_count = arrow_count\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{super().describe()}, Arrows: {self.arrow_count}\"\n",
    "\n",
    "\n",
    "class Wizard(Hero):\n",
    "    def __init__(self, name, level, spell_count):\n",
    "        super().__init__(name, level)\n",
    "        self.spell_count = spell_count\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{super().describe()}, Spells: {self.spell_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robin, Level 10 Hero, Arrows: 20\n",
      "Merlin, Level 12 Hero, Spells: 5\n"
     ]
    }
   ],
   "source": [
    "archer = Archer(\"Robin\", 10, 20)\n",
    "wizard = Wizard(\"Merlin\", 12, 5)\n",
    "\n",
    "print(archer.describe())\n",
    "print(wizard.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Private Attributes, getters and setters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getter used\n",
      "5\n",
      "5\n",
      "Getter used\n",
      "6\n",
      "Invalid level: 3. Must be greater than current level 6.\n"
     ]
    }
   ],
   "source": [
    "class Hero:\n",
    "    def __init__(self, name, level):\n",
    "        self.name = name\n",
    "        self._level = level\n",
    "\n",
    "    @property\n",
    "    def level(self):\n",
    "        print(\"Getter used\")\n",
    "        return self._level\n",
    "\n",
    "    @level.setter\n",
    "    def level(self, new_level):\n",
    "        if new_level > self._level:\n",
    "            self._level = new_level\n",
    "        else:\n",
    "            print(\n",
    "                f\"Invalid level: {new_level}. Must be greater than current level {self._level}.\"\n",
    "            )\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Hero\"\n",
    "\n",
    "\n",
    "hero1 = Hero(\"Merlin\", 5)\n",
    "print(hero1.level)\n",
    "print(hero1._level)\n",
    "hero1.level = 6\n",
    "print(hero1.level)\n",
    "hero1.level = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dunder methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hero:\n",
    "    def __init__(self, name, level):\n",
    "        self.name = name\n",
    "        self._level = level\n",
    "\n",
    "    @property\n",
    "    def level(self):\n",
    "        print(\"Getter used\")\n",
    "        return self._level\n",
    "\n",
    "    @level.setter\n",
    "    def level(self, new_level):\n",
    "        if new_level > self._level:\n",
    "            self._level = new_level\n",
    "        else:\n",
    "            print(\n",
    "                f\"Invalid level: {new_level}. Must be greater than current level {self._level}.\"\n",
    "            )\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{self.name}, Level {self.level} Hero\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}, Level {self._level} Hero\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Hero(f\"{self.name}&{other.name}\", self.level + other.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merlin, Level 5 Hero\n",
      "Melchor, Level 5 Hero\n",
      "Getter used\n",
      "Getter used\n",
      "Merlin&Melchor, Level 10 Hero\n"
     ]
    }
   ],
   "source": [
    "hero1 = Hero(\"Merlin\", 5)\n",
    "hero2 = Hero(\"Melchor\", 5)\n",
    "print(hero1)\n",
    "print(hero2)\n",
    "print(hero1 + hero2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create the subclasses again to be able to use the dunder methods from inside the childclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Archer(Hero):\n",
    "    def __init__(self, name, level, arrow_count):\n",
    "        super().__init__(name, level)\n",
    "        self.arrow_count = arrow_count\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{super().describe()}, Arrows: {self.arrow_count}\"\n",
    "\n",
    "\n",
    "class Wizard(Hero):\n",
    "    def __init__(self, name, level, spell_count):\n",
    "        super().__init__(name, level)\n",
    "        self.spell_count = spell_count\n",
    "\n",
    "    def describe(self):\n",
    "        return f\"{super().describe()}, Spells: {self.spell_count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Team:\n",
    "    def __init__(self, *heroes):\n",
    "        self.heroes = heroes\n",
    "\n",
    "    def describe(self):\n",
    "        for hero in self.heroes:\n",
    "            print(hero.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getter used\n",
      "Robin, Level 10 Hero, Arrows: 20\n",
      "Getter used\n",
      "Merlin, Level 12 Hero, Spells: 5\n"
     ]
    }
   ],
   "source": [
    "archer = Archer(\"Robin\", 10, 20)\n",
    "wizard = Wizard(\"Merlin\", 12, 5)\n",
    "\n",
    "team = Team(archer, wizard)\n",
    "\n",
    "team.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abstract Classes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class Hero(ABC):\n",
    "    def __init__(self, name, level):\n",
    "        self.name = name\n",
    "        self._level = level\n",
    "\n",
    "    @property\n",
    "    def level(self):\n",
    "        return self._level\n",
    "\n",
    "    @level.setter\n",
    "    def level(self, new_level):\n",
    "        if new_level > self._level:\n",
    "            self._level = new_level\n",
    "        else:\n",
    "            print(\n",
    "                f\"Invalid level: {new_level}. Must be greater than current level {self._level}.\"\n",
    "            )\n",
    "\n",
    "    @abstractmethod\n",
    "    def describe(self):\n",
    "        pass\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.describe()\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Hero(f\"{self.name}&{other.name}\", self.level + other.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = \"\"\"\n",
    "\n",
    ". conservation their of importance the and extinction imminent their of implications the discuss also We . survival its ensure to needed strategies the discuss and Quetzal Resplendent the of conservation and , ecology , biology the examine we , article this In . regulations hunting and initiatives protection habitat as such , efforts conservation of number a to subject being species the to led has This . decreasing steadily is size population its and , List Red IUCN the on vulnerable as listed now is It . overhunting and destruction habitat to due years recent in declined have estimates population but , abundant be to considered long was Quetzal Resplendent The . length1 in cm 52 reach can which , feathers tail long and plumage red and green bright its for notable is It . family the in species widespread most and best-known the is and family Trogonidae the of member a is It . America South and Central to native bird iridescent , colorful of species a is ) mocinno Pharomachrus ( Quetzal Resplendent The\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Resplendent Quetzal ( Pharomachrus mocinno ) is a species of colorful , iridescent bird native to Central and South America . It is a member of the Trogonidae family and is the best-known and most widespread species in the family . It is notable for its bright green and red plumage and long tail feathers , which can reach 52 cm in length1 . The Resplendent Quetzal was long considered to be abundant , but population estimates have declined in recent years due to habitat destruction and overhunting . It is now listed as vulnerable on the IUCN Red List , and its population size is steadily decreasing . This has led to the species being subject to a number of conservation efforts , such as habitat protection initiatives and hunting regulations . In this article , we examine the biology , ecology , and conservation of the Resplendent Quetzal and discuss the strategies needed to ensure its survival . We also discuss the implications of their imminent extinction and the importance of their conservation .\n"
     ]
    }
   ],
   "source": [
    "def flip_string(text):\n",
    "  # Split the string on spaces\n",
    "  words = text.split()\n",
    "\n",
    "  # Reverse the order of the words\n",
    "  flipped_words = words[::-1]\n",
    "\n",
    "  # Join the flipped words back into a string with spaces\n",
    "  return \" \".join(flipped_words)\n",
    "\n",
    "# Example usage\n",
    "text = text2\n",
    "flipped_text = flip_string(text)\n",
    "print(flipped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"\"\".noitavresnoc rieht fo ecnatropmi eht dna noitcnitxe tnenimmi rieht fo snoitacilpmi eht ssucsid osla eW .lavivrus sti erusne ot dedeen seigetarts eht ssucsid dna lazteuQ tnednelpseR eht fo noitavresnoc dna ,ygoloce ,ygoloib eht enimaxe ew ,elcitra siht nI\n",
    "\n",
    ".snoitaluger gnitnuh dna sevitaitini noitcetorp tatibah sa hcus ,stroffe noitavresnoc fo rebmun a ot tcejbus gnieb seiceps eht ot del sah sihT .gnisaerced ylidaets si ezis noitalupop sti dna ,tsiL deR NCUI eht no elbarenluv sa detsil won si tI .gnitnuhrevo dna noitcurtsed tatibah ot eud sraey tnecer ni denilced evah setamitse noitalupop tub ,tnadnuba eb ot deredisnoc gnol saw lazteuQ tnednelpseR ehT\n",
    "\n",
    ".1htgnel ni mc 25 hcaer nac hcihw ,srehtaef liat gnol dna egamulp der dna neerg thgirb sti rof elbaton si tI .ylimaf eht ni seiceps daerpsediw tsom dna nwonk-tseb eht si dna ylimaf eadinogorT eht fo rebmem a si tI .aciremA htuoS dna lartneC ot evitan drib tnecsediri ,lufroloc fo seiceps a si )onnicom surhcamorahP( lazteuQ tnednelpseR ehT \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reversed:  The Resplendent Quetzal (Pharomachrus mocinno) is a species of colorful, iridescent bird native to Central and South America. It is a member of the Trogonidae family and is the best-known and most widespread species in the family. It is notable for its bright green and red plumage and long tail feathers, which can reach 52 cm in length1.\n",
      "\n",
      "The Resplendent Quetzal was long considered to be abundant, but population estimates have declined in recent years due to habitat destruction and overhunting. It is now listed as vulnerable on the IUCN Red List, and its population size is steadily decreasing. This has led to the species being subject to a number of conservation efforts, such as habitat protection initiatives and hunting regulations.\n",
      "\n",
      "In this article, we examine the biology, ecology, and conservation of the Resplendent Quetzal and discuss the strategies needed to ensure its survival. We also discuss the implications of their imminent extinction and the importance of their conservation.\n"
     ]
    }
   ],
   "source": [
    "def reverse_sentence(sentence):\n",
    "    return sentence[::-1]\n",
    "\n",
    "# Example usage\n",
    "original_sentence = text3\n",
    "reversed_sentence = reverse_sentence(original_sentence)\n",
    "\n",
    "print(\"Reversed:\", reversed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCS50P\u001b[m\u001b[m/             pybasic.ipynb      typehinting.ipynb\n",
      "oop.ipynb          \u001b[34mtesting\u001b[m\u001b[m/\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataprep2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[176], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m text[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Reverse characters\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Load the CSV data\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataprep2.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Add new columns with flipped outputs\u001b[39;00m\n\u001b[1;32m     15\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_output1\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(flip_string)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataprep2.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the functions for flipping\n",
    "def flip_string(text):\n",
    "  words = text.split()\n",
    "  return \" \".join(words[::-1])  # Reverse the order of words\n",
    "\n",
    "def reverse_char(text):\n",
    "  return text[::-1]  # Reverse characters\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(\"dataprep2.csv\")\n",
    "\n",
    "# Add new columns with flipped outputs\n",
    "df[\"new_output1\"] = df[\"output\"].apply(flip_string)\n",
    "df[\"new_output2\"] = df[\"output\"].apply(reverse_char)\n",
    "\n",
    "# Save the modified dataframe\n",
    "df.to_csv(\"first_batch_data2.csv\", index=False)\n",
    "\n",
    "print(\"CSV processed and saved as first_batch_data2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV processed and saved as first_batch_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the functions for flipping\n",
    "def flip_string(text):\n",
    "  words = text.split()\n",
    "  return \" \".join(words[::-1])  # Reverse the order of words\n",
    "\n",
    "def reverse_char(text):\n",
    "  return text[::-1]  # Reverse characters\n",
    "\n",
    "def process_text_v3(sentence):\n",
    "    # Step 1: Add spaces\n",
    "    sentence = re.sub(r\"(?<!\\s)([!\\\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~])(?=(\\s|$))\", r\" \\1\", sentence)\n",
    "    sentence = re.sub(r\"([\\(\\[\\{])\", r\"\\1 \", sentence)\n",
    "    \n",
    "    # Step 2: Split and reverse\n",
    "    words = sentence.split()\n",
    "    words.reverse()\n",
    "    \n",
    "    # Step 4: Join the elements\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Load the CSV data\n",
    "df = pd.read_csv(\"dataprep_.csv\")\n",
    "\n",
    "# Apply text processing and add a new column\n",
    "df[\"new_output1\"] = df[\"output\"].apply(process_text_v3)\n",
    "df[\"new_output2\"] = df[\"output\"].apply(reverse_char)\n",
    "\n",
    "# Save the modified dataframe\n",
    "df.to_csv(\"first_batch_data.csv\", index=False)\n",
    "\n",
    "print(\"CSV processed and saved as first_batch_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data added to 'word_data_train' column.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the concatenation pattern\n",
    "pattern = \"<s>[INST] {} [/INST] {} </s>\"\n",
    "\n",
    "def process_row(row):\n",
    "  instruction = row[\"instruction\"]\n",
    "  output = row[\"output\"]\n",
    "  # Concatenate data using the pattern\n",
    "  train_data = pattern.format(instruction, output)\n",
    "  return train_data\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"word_data.csv\")\n",
    "\n",
    "# Create a new empty column for train data\n",
    "df[\"word_data_train\"] = None\n",
    "\n",
    "# Apply the processing function to each row (one cell at a time)\n",
    "df[\"word_data_train\"] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Load the \"train_data\" column as a separate DataFrame\n",
    "train_df = df[[\"word_data_train\"]]  # Select only the train_data column\n",
    "\n",
    "# You can now save the train_df to a new CSV file if needed\n",
    "train_df.to_csv(\"word_data_train.csv\", index=False)\n",
    "\n",
    "print(\"Processed data added to 'word_data_train' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data added to 'char_train_data' column and exported char_train.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the concatenation pattern\n",
    "pattern = \"<s>[INST] {} [/INST] {} </s>\"\n",
    "\n",
    "def process_row(row):\n",
    "  instruction = row[\"instruction\"]\n",
    "  output = row[\"output\"]\n",
    "  # Concatenate data using the pattern\n",
    "  train_data = pattern.format(instruction, output)\n",
    "  return train_data\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"char_data.csv\")\n",
    "\n",
    "# Create a new empty column for train data\n",
    "df[\"char_train_data\"] = None\n",
    "\n",
    "# Apply the processing function to each row (one cell at a time)\n",
    "df[\"char_train_data\"] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Load the \"train_data\" column as a separate DataFrame\n",
    "train_df = df[[\"char_train_data\"]]  # Select only the train_data column\n",
    "\n",
    "# You can now save the train_df to a new CSV file if needed\n",
    "train_df.to_csv(\"char_train.csv\", index=False)\n",
    "\n",
    "print(\"Processed data added to 'char_train_data' column and exported char_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'instruction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'instruction'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Apply the processing function to each row (one cell at a time)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_row\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Load the \"train_data\" column as a separate DataFrame\u001b[39;00m\n\u001b[1;32m     23\u001b[0m train_df \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mordered\u001b[39m\u001b[38;5;124m\"\u001b[39m]]  \u001b[38;5;66;03m# Select only the train_data column\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/frame.py:10361\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10347\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10349\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10350\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10351\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10359\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10360\u001b[0m )\n\u001b[0;32m> 10361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[53], line 7\u001b[0m, in \u001b[0;36mprocess_row\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_row\u001b[39m(row):\n\u001b[0;32m----> 7\u001b[0m   instruction \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minstruction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m   output \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      9\u001b[0m   \u001b[38;5;66;03m# Concatenate data using the pattern\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/series.py:1112\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/series.py:1228\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1225\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1228\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'instruction'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the concatenation pattern\n",
    "pattern = \"<s>[INST] {} [/INST] {} </s>\"\n",
    "\n",
    "def process_row(row):\n",
    "  instruction = row[\"instruction\"]\n",
    "  output = row[\"output\"]\n",
    "  # Concatenate data using the pattern\n",
    "  train_data = pattern.format(instruction, output)\n",
    "  return train_data\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"ordered.csv\")\n",
    "\n",
    "# Create a new empty column for train data\n",
    "df[\"ordered\"] = None\n",
    "\n",
    "# Apply the processing function to each row (one cell at a time)\n",
    "df[\"ordered\"] = df.apply(process_row, axis=1)\n",
    "\n",
    "# Load the \"train_data\" column as a separate DataFrame\n",
    "train_df = df[[\"ordered\"]]  # Select only the train_data column\n",
    "\n",
    "# You can now save the train_df to a new CSV file if needed\n",
    "train_df.to_csv(\"ordered.csv\", index=False)\n",
    "\n",
    "print(\"Processed data added to 'ordered' column.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I live in a house factory cake. intend I live here longer.\n"
     ]
    }
   ],
   "source": [
    "def check_new_words(sentence1, sentence2):\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "    \n",
    "    combinations1 = [' '.join(words1[i:i+3]) for i in range(len(words1)-2)]\n",
    "    combinations2 = [' '.join(words2[i:i+3]) for i in range(len(words2)-2)]\n",
    "    \n",
    "    same_combinations = set(combinations1) & set(combinations2)\n",
    "    different_combinations = set(combinations2) - same_combinations\n",
    "    \n",
    "    new_words = []\n",
    "    for combination in different_combinations:\n",
    "        combination_words = combination.split()\n",
    "        if len(combination_words) == 3:\n",
    "            word1, word2, word3 = combination_words\n",
    "            if word1 in words1 and word3 in words1:\n",
    "                index1 = words1.index(word1)\n",
    "                index3 = words1.index(word3)\n",
    "                if index3 == index1 + 2:\n",
    "                    new_words.append((word2, index1 + 1))\n",
    "    \n",
    "    new_sentence = []\n",
    "    for i, word in enumerate(words1):\n",
    "        if i not in [index for _, index in new_words]:\n",
    "            new_sentence.append(word)\n",
    "    \n",
    "    new_sentence.extend([word for word, _ in new_words])\n",
    "    \n",
    "    return ' '.join(new_sentence)\n",
    "\n",
    "sentence1 = \"I live in a house factory cake. intend I live here longer.\"\n",
    "sentence2 = \"I live in the cake factory house. I intend to live here longer.\"\n",
    "\n",
    "new_sentence = check_new_words(sentence1, sentence2)\n",
    "print(new_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: I live in a house factory cake. I intend to live here longer.\n",
      "Modified Sentence 2: live I intend to live here longer. in the cake factory house. I\n"
     ]
    }
   ],
   "source": [
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def get_combinations(sentence):\n",
    "        words = sentence.split()\n",
    "        return [\" \".join(words[i:i+3]) for i in range(len(words) - 2)]\n",
    "\n",
    "    def move_word_to_end(sentence, word):\n",
    "        words = sentence.split()\n",
    "        words.remove(word)\n",
    "        return \" \".join(words) + \" \" + word\n",
    "\n",
    "    combinations1 = get_combinations(sentence1)\n",
    "    combinations2 = get_combinations(sentence2)\n",
    "\n",
    "    unique_combinations = [comb for comb in combinations2 if comb not in combinations1]\n",
    "\n",
    "    for combination in unique_combinations:\n",
    "        words1 = combination.split()\n",
    "        words2 = sentence2.split()\n",
    "\n",
    "        if len(words1) == 3 and words1[1] != words2[words2.index(words1[1]) - 1]:\n",
    "            sentence2 = move_word_to_end(sentence2, words1[1])\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a house factory cake. I intend to live here longer.\"\n",
    "sentence2 = \"I live in the cake factory house. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: live I intend to live here longer. in a house factory cake. I\n",
      "Modified Sentence 2: live I intend to live here longer. in the cake factory house. I\n"
     ]
    }
   ],
   "source": [
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def get_combinations(sentence):\n",
    "        words = sentence.split()\n",
    "        return [\" \".join(words[i:i+3]) for i in range(len(words) - 2)]\n",
    "\n",
    "    def move_word_to_end(sentence, word):\n",
    "        words = sentence.split()\n",
    "        words.remove(word)\n",
    "        return \" \".join(words) + \" \" + word\n",
    "\n",
    "    combinations1 = get_combinations(sentence1)\n",
    "    combinations2 = get_combinations(sentence2)\n",
    "\n",
    "    unique_combinations1 = [comb for comb in combinations1 if comb not in combinations2]\n",
    "    unique_combinations2 = [comb for comb in combinations2 if comb not in combinations1]\n",
    "\n",
    "    for combination in unique_combinations1:\n",
    "        words1 = combination.split()\n",
    "        words1_sentence = sentence1.split()\n",
    "\n",
    "        if len(words1) == 3 and words1[1] != words1_sentence[words1_sentence.index(words1[1]) - 1]:\n",
    "            sentence1 = move_word_to_end(sentence1, words1[1])\n",
    "\n",
    "    for combination in unique_combinations2:\n",
    "        words2 = combination.split()\n",
    "        words2_sentence = sentence2.split()\n",
    "\n",
    "        if len(words2) == 3 and words2[1] != words2_sentence[words2_sentence.index(words2[1]) - 1]:\n",
    "            sentence2 = move_word_to_end(sentence2, words2[1])\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a house factory cake. I intend to live here longer.\"\n",
    "sentence2 = \"I live in the cake factory house. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: live I intend to live here longer in a house factory cake I\n",
      "Modified Sentence 2: live I intend to live here longer in the cake factory house I\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def get_combinations(sentence):\n",
    "        words = sentence.split()\n",
    "        return [\" \".join(words[i:i+3]) for i in range(len(words) - 2)]\n",
    "\n",
    "    def move_word_to_end(sentence, word):\n",
    "        words = sentence.split()\n",
    "        words.remove(word)\n",
    "        return \" \".join(words) + \" \" + word\n",
    "\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    combinations1 = get_combinations(sentence1)\n",
    "    combinations2 = get_combinations(sentence2)\n",
    "\n",
    "    unique_combinations1 = [comb for comb in combinations1 if comb not in combinations2]\n",
    "    unique_combinations2 = [comb for comb in combinations2 if comb not in combinations1]\n",
    "\n",
    "    for combination in unique_combinations1:\n",
    "        words = combination.split()\n",
    "        if len(words) == 3:\n",
    "            sentence1 = move_word_to_end(sentence1, words[1])\n",
    "\n",
    "    for combination in unique_combinations2:\n",
    "        words = combination.split()\n",
    "        if len(words) == 3:\n",
    "            sentence2 = move_word_to_end(sentence2, words[1])\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a house factory cake. I intend to live here longer.\"\n",
    "sentence2 = \"I live in the cake factory house. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: I live factory cake I intend to live here longer in a house\n",
      "Modified Sentence 2: I live factory cake I intend to live here longer in the house\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def get_combinations(sentence):\n",
    "        words = sentence.split()\n",
    "        return [\" \".join(words[i:i+3]) for i in range(len(words) - 2)]\n",
    "\n",
    "    def move_word_to_end(sentence, word):\n",
    "        words = sentence.split()\n",
    "        words.remove(word)\n",
    "        return \" \".join(words) + \" \" + word\n",
    "\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    combinations1 = get_combinations(sentence1)\n",
    "    combinations2 = get_combinations(sentence2)\n",
    "\n",
    "    unique_combinations1 = [comb.split()[1] for comb in combinations1 if comb not in combinations2]\n",
    "    unique_combinations2 = [comb.split()[1] for comb in combinations2 if comb not in combinations1]\n",
    "\n",
    "    for word in unique_combinations1:\n",
    "        sentence1 = move_word_to_end(sentence1, word)\n",
    "\n",
    "    for word in unique_combinations2:\n",
    "        sentence2 = move_word_to_end(sentence2, word)\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a house factory cake. I intend to live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: I live in house factory cake I intend live here longer a\n",
      "Modified Sentence 2: I live in the house factory cake I intend live here longer to\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_word_to_end(sentence, word):\n",
    "        words = sentence.split()\n",
    "        words.remove(word)\n",
    "        return \" \".join(words) + \" \" + word\n",
    "\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    words1 = set(sentence1.split())\n",
    "    words2 = set(sentence2.split())\n",
    "\n",
    "    unique_word1 = words1.difference(words2)\n",
    "    unique_word2 = words2.difference(words1)\n",
    "\n",
    "    if unique_word1:\n",
    "        sentence1 = move_word_to_end(sentence1, unique_word1.pop())\n",
    "\n",
    "    if unique_word2:\n",
    "        sentence2 = move_word_to_end(sentence2, unique_word2.pop())\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a house factory cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: I live in factory house cake intend live here longer a\n",
      "Modified Sentence 2: I live in house factory cake I intend live here longer to the\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_word_to_end(sentence, unique_words):\n",
    "        words = sentence.split()\n",
    "        for word in unique_words:\n",
    "            if word in words:\n",
    "                words.remove(word)\n",
    "        return \" \".join(words) + \" \" + \" \".join(unique_words)\n",
    "\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation))\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    words1 = set(sentence1.split())\n",
    "    words2 = set(sentence2.split())\n",
    "\n",
    "    unique_words1 = words1.difference(words2)\n",
    "    unique_words2 = words2.difference(words1)\n",
    "\n",
    "    sentence1 = move_word_to_end(sentence1, unique_words1)\n",
    "    sentence2 = move_word_to_end(sentence2, unique_words2)\n",
    "\n",
    "    return sentence1, sentence2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live in a factory house cake. intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2 = move_different_word_to_end(sentence1, sentence2)\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Modified Sentence 2:\", result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: i live factory house cake i intend live here longer a\n",
      "Retained Sentence 1: i live factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('live', 1), ('factory', 3), ('house', 4), ('cake', 5), ('i', 6), ('intend', 7), ('live', 8), ('here', 9), ('longer', 10)]\n",
      "Moved Words 1: [('a', 2)]\n",
      "Modified Sentence 2: i live house factory cake i intend live here longer in the to\n",
      "Retained Sentence 2: i live house factory cake i intend live here longer\n",
      "Retained Words 2: [('i', 0), ('live', 1), ('house', 4), ('factory', 5), ('cake', 6), ('i', 7), ('intend', 8), ('live', 10), ('here', 11), ('longer', 12)]\n",
      "Moved Words 2: [('in', 2), ('the', 3), ('to', 9)]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = [(word, idx) for idx, word in enumerate(sentence_words) if word not in words_to_move]\n",
    "        moved_words = [(word, idx) for idx, word in enumerate(sentence_words) if word in words_to_move]\n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    unique_words1 = set(words1).difference(set(words2))\n",
    "    unique_words2 = set(words2).difference(set(words1))\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: i live factory house cake i intend live here longer a\n",
      "Retained Sentence 1: i live factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('live', 1), ('factory', 3), ('house', 4), ('cake', 5), ('i', 6), ('intend', 7), ('live', 8), ('here', 9), ('longer', 10)]\n",
      "Moved Words 1: [('a', 2)]\n",
      "Modified Sentence 2: i live house factory cake i intend live here longer in the to\n",
      "Retained Sentence 2: i live house factory cake i intend live here longer\n",
      "Retained Words 2: [('i', 0), ('live', 1), ('house', 4), ('factory', 5), ('cake', 6), ('i', 7), ('intend', 8), ('live', 10), ('here', 11), ('longer', 12)]\n",
      "Moved Words 2: [('in', 2), ('the', 3), ('to', 9)]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = [(word, idx) for idx, word in enumerate(sentence_words) if word not in words_to_move]\n",
    "        moved_words = [(word, idx) for idx, word in enumerate(sentence_words) if word in words_to_move]\n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    unique_words1 = set(words1).difference(set(words2))\n",
    "    unique_words2 = set(words2).difference(set(words1))\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I live a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: i factory house cake i intend live here longer lives a\n",
      "Retained Sentence 1: i factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('factory', 3), ('house', 4), ('cake', 5), ('i', 6), ('intend', 7), ('live', 8), ('here', 9), ('longer', 10)]\n",
      "Moved Words 1: [('lives', 1), ('a', 2)]\n",
      "Modified Sentence 2: i live house factory cake i intend live here longer in the to\n",
      "Retained Sentence 2: i live house factory cake i intend live here longer\n",
      "Retained Words 2: [('i', 0), ('house', 4)]\n",
      "Moved Words 2: [('in', 2), ('the', 3), ('to', 9), ('live', 1), ('factory', 5), ('cake', 6), ('i', 7), ('intend', 8), ('live', 10), ('here', 11), ('longer', 12)]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = [(word, idx) for idx, word in enumerate(sentence_words) if word not in words_to_move]\n",
    "        moved_words = [(word, idx) for idx, word in enumerate(sentence_words) if word in words_to_move]\n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    unique_words1 = set(words1).difference(set(words2))\n",
    "    unique_words2 = set(words2).difference(set(words1))\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "def update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2):\n",
    "    # Create a list to mark which indices in retained_words1 have been matched\n",
    "    matched_indices = [False] * len(retained_words1)\n",
    "    \n",
    "    # Find words in retained_words2 that do not match their position in retained_words1\n",
    "    additional_moved_words2 = []\n",
    "    \n",
    "    for idx2, (word2, pos2) in enumerate(retained_words2):\n",
    "        found_match = False\n",
    "        for idx1, (word1, pos1) in enumerate(retained_words1):\n",
    "            if word2 == word1 and not matched_indices[idx1] and idx2 == idx1:\n",
    "                matched_indices[idx1] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            additional_moved_words2.append((word2, pos2))\n",
    "    \n",
    "    # Update moved_words2 with these additional words\n",
    "    moved_words2.extend(additional_moved_words2)\n",
    "    \n",
    "    # Filter retained_words2 to remove the words that have been moved\n",
    "    retained_words2 = [(word, idx) for word, idx in retained_words2 if (word, idx) not in additional_moved_words2]\n",
    "    \n",
    "    return retained_words2, moved_words2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I lives a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "# Update moved_words2 based on position comparison\n",
    "retained_words2, moved_words2 = update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2)\n",
    "\n",
    "# Print results\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: i factory house cake i intend live here longer lives a\n",
      "Retained Sentence 1: i factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('factory', 3), ('house', 4), ('cake', 5), ('i', 6), ('intend', 7), ('live', 8), ('here', 9), ('longer', 10)]\n",
      "Moved Words 1: [('lives', 1), ('a', 2)]\n",
      "Modified Sentence 2: i house factory cake i intend here longer live in the to live\n",
      "Retained Sentence 2: i cake i intend\n",
      "Retained Words 2: [('i', 0), ('cake', 6), ('i', 7), ('intend', 8)]\n",
      "Moved Words 2: [('live', 1), ('in', 2), ('the', 3), ('to', 9), ('live', 10), ('house', 4), ('factory', 5), ('here', 11), ('longer', 12)]\n",
      "\n",
      "Second Example:\n",
      "Modified Sentence 1: i factory house cake i intend live here longer lives a\n",
      "Retained Sentence 1: i factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('factory', 3), ('house', 4), ('cake', 5), ('i', 6), ('intend', 7), ('live', 8), ('here', 9), ('longer', 10)]\n",
      "Moved Words 1: [('lives', 1), ('a', 2)]\n",
      "Modified Sentence 2: i house factory cake i intend here longer live in the to live\n",
      "Retained Sentence 2: i cake i intend\n",
      "Retained Words 2: [('i', 0), ('cake', 6), ('i', 7), ('intend', 8)]\n",
      "Moved Words 2: [('live', 1), ('in', 2), ('the', 3), ('to', 9), ('live', 10), ('house', 4), ('factory', 5), ('here', 11), ('longer', 12)]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = []\n",
    "        moved_words = []\n",
    "        words_to_move_count = Counter(words_to_move)\n",
    "        \n",
    "        for idx, word in enumerate(sentence_words):\n",
    "            if words_to_move_count[word] > 0:\n",
    "                moved_words.append((word, idx))\n",
    "                words_to_move_count[word] -= 1\n",
    "            else:\n",
    "                retained_words.append((word, idx))\n",
    "        \n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    counter1 = Counter(words1)\n",
    "    counter2 = Counter(words2)\n",
    "    unique_words1 = counter1 - counter2\n",
    "    unique_words2 = counter2 - counter1\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "def update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2):\n",
    "    # Create a list to mark which indices in retained_words1 have been matched\n",
    "    matched_indices = [False] * len(retained_words1)\n",
    "    \n",
    "    # Find words in retained_words2 that do not match their position in retained_words1\n",
    "    additional_moved_words2 = []\n",
    "    \n",
    "    for idx2, (word2, pos2) in enumerate(retained_words2):\n",
    "        found_match = False\n",
    "        for idx1, (word1, pos1) in enumerate(retained_words1):\n",
    "            if word2 == word1 and not matched_indices[idx1] and idx2 == idx1:\n",
    "                matched_indices[idx1] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            additional_moved_words2.append((word2, pos2))\n",
    "    \n",
    "    # Update moved_words2 with these additional words\n",
    "    moved_words2.extend(additional_moved_words2)\n",
    "    \n",
    "    # Filter retained_words2 to remove the words that have been moved\n",
    "    retained_words2 = [(word, idx) for word, idx in retained_words2 if (word, idx) not in additional_moved_words2]\n",
    "    \n",
    "    return retained_words2, moved_words2\n",
    "\n",
    "def get_final_sentences_and_words(sentence1, sentence2):\n",
    "    result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "    # Update moved_words2 based on position comparison\n",
    "    retained_words2, moved_words2 = update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2)\n",
    "\n",
    "    # Form the final retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"I lives a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n",
    "\n",
    "# Test with another example\n",
    "sentence1 = \"I lives a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results for the second example\n",
    "print(\"\\nSecond Example:\")\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Second Example:\n",
      "Modified Sentence 1: i in factory house cake i intend live here longer lives a\n",
      "Retained Sentence 1: i in factory house cake i intend live here longer\n",
      "Retained Words 1: [('i', 0), ('in', 2), ('factory', 4), ('house', 5), ('cake', 6), ('i', 7), ('intend', 8), ('live', 9), ('here', 10), ('longer', 11)]\n",
      "Moved Words 1: [('lives', 1), ('a', 3)]\n",
      "Modified Sentence 2: i in house factory cake i intend live here longer live the to\n",
      "Retained Sentence 2: i in cake i intend live here longer\n",
      "Retained Words 2: [('i', 0), ('in', 2), ('cake', 6), ('i', 7), ('intend', 8), ('live', 10), ('here', 11), ('longer', 12)]\n",
      "Moved Words 2: [('live', 1), ('the', 3), ('to', 9), ('house', 4), ('factory', 5)]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = []\n",
    "        moved_words = []\n",
    "        words_to_move_count = Counter(words_to_move)\n",
    "        \n",
    "        for idx, word in enumerate(sentence_words):\n",
    "            if words_to_move_count[word] > 0:\n",
    "                moved_words.append((word, idx))\n",
    "                words_to_move_count[word] -= 1\n",
    "            else:\n",
    "                retained_words.append((word, idx))\n",
    "        \n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    counter1 = Counter(words1)\n",
    "    counter2 = Counter(words2)\n",
    "    unique_words1 = counter1 - counter2\n",
    "    unique_words2 = counter2 - counter1\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "def update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2):\n",
    "    # Create a list to mark which indices in retained_words1 have been matched\n",
    "    matched_indices = [False] * len(retained_words1)\n",
    "    \n",
    "    # Find words in retained_words2 that do not match their position in retained_words1\n",
    "    additional_moved_words2 = []\n",
    "    \n",
    "    for idx2, (word2, pos2) in enumerate(retained_words2):\n",
    "        found_match = False\n",
    "        for idx1, (word1, pos1) in enumerate(retained_words1):\n",
    "            if word2 == word1 and not matched_indices[idx1] and idx2 == idx1:\n",
    "                matched_indices[idx1] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            additional_moved_words2.append((word2, pos2))\n",
    "    \n",
    "    # Update moved_words2 with these additional words\n",
    "    moved_words2.extend(additional_moved_words2)\n",
    "    \n",
    "    # Filter retained_words2 to remove the words that have been moved\n",
    "    retained_words2 = [(word, idx) for word, idx in retained_words2 if (word, idx) not in additional_moved_words2]\n",
    "    \n",
    "    return retained_words2, moved_words2\n",
    "\n",
    "def get_final_sentences_and_words(sentence1, sentence2):\n",
    "    result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "    # Update moved_words2 based on position comparison\n",
    "    retained_words2, moved_words2 = update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2)\n",
    "\n",
    "    # Form the final retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# # Example usage\n",
    "# sentence1 = \"I lives a factory house cake. I intend live here longer.\"\n",
    "# sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "# result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# # Print results\n",
    "# print(\"Modified Sentence 1:\", result1)\n",
    "# print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "# print(\"Retained Words 1:\", retained_words1)\n",
    "# print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "# print(\"Modified Sentence 2:\", result2)\n",
    "# print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "# print(\"Retained Words 2:\", retained_words2)\n",
    "# print(\"Moved Words 2:\", moved_words2)\n",
    "\n",
    "# Test with another example\n",
    "sentence1 = \"I lives in a factory house cake. I intend live here longer.\"\n",
    "sentence2 = \"I live in the house factory cake. I intend to live here longer.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results for the second example\n",
    "print(\"\\nSecond Example:\")\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example: \n",
      "\n",
      "Modified Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories be a spend\n",
      "Retained Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories\n",
      "Retained Words 1: [('canteen', 0), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17), ('a', 18), ('laboratories', 19)]\n",
      "Moved Words 1: [('be', 1), ('a', 2), ('spend', 15)]\n",
      "\n",
      "\n",
      "Modified Sentence 2: canteen a great place to catch up with friends and i have always loved time in laboratories is spending\n",
      "Retained Sentence 2: canteen laboratories\n",
      "Retained Words 2: [('canteen', 0), ('laboratories', 18)]\n",
      "Moved Words 2: [('is', 1), ('spending', 15), ('a', 2), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17)]\n",
      "Moved Words 2 (JSON) for the second example:\n",
      "{\n",
      "    \"is\": 1,\n",
      "    \"a\": 2,\n",
      "    \"great\": 3,\n",
      "    \"place\": 4,\n",
      "    \"to\": 5,\n",
      "    \"catch\": 6,\n",
      "    \"up\": 7,\n",
      "    \"with\": 8,\n",
      "    \"friends\": 9,\n",
      "    \"and\": 10,\n",
      "    \"i\": 11,\n",
      "    \"have\": 12,\n",
      "    \"always\": 13,\n",
      "    \"loved\": 14,\n",
      "    \"spending\": 15,\n",
      "    \"time\": 16,\n",
      "    \"in\": 17\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "from collections import Counter\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = []\n",
    "        moved_words = []\n",
    "        words_to_move_count = Counter(words_to_move)\n",
    "        \n",
    "        for idx, word in enumerate(sentence_words):\n",
    "            if words_to_move_count[word] > 0:\n",
    "                moved_words.append((word, idx))\n",
    "                words_to_move_count[word] -= 1\n",
    "            else:\n",
    "                retained_words.append((word, idx))\n",
    "        \n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation and convert sentences to lowercase\n",
    "    sentence1 = sentence1.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "    sentence2 = sentence2.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    counter1 = Counter(words1)\n",
    "    counter2 = Counter(words2)\n",
    "    unique_words1 = counter1 - counter2\n",
    "    unique_words2 = counter2 - counter1\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    # Combine retained and moved words to form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    \n",
    "    # Form retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "def update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2):\n",
    "    # Create a list to mark which indices in retained_words1 have been matched\n",
    "    matched_indices = [False] * len(retained_words1)\n",
    "    \n",
    "    # Find words in retained_words2 that do not match their position in retained_words1\n",
    "    additional_moved_words2 = []\n",
    "    \n",
    "    for idx2, (word2, pos2) in enumerate(retained_words2):\n",
    "        found_match = False\n",
    "        for idx1, (word1, pos1) in enumerate(retained_words1):\n",
    "            if word2 == word1 and not matched_indices[idx1] and idx2 == idx1:\n",
    "                matched_indices[idx1] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            additional_moved_words2.append((word2, pos2))\n",
    "    \n",
    "    # Update moved_words2 with these additional words\n",
    "    moved_words2.extend(additional_moved_words2)\n",
    "    \n",
    "    # Filter retained_words2 to remove the words that have been moved\n",
    "    retained_words2 = [(word, idx) for word, idx in retained_words2 if (word, idx) not in additional_moved_words2]\n",
    "    \n",
    "    return retained_words2, moved_words2\n",
    "\n",
    "def get_final_sentences_and_words(sentence1, sentence2):\n",
    "    result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "    # Update moved_words2 based on position comparison\n",
    "    retained_words2, moved_words2 = update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2)\n",
    "\n",
    "    # Form the final retained sentences\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# Test with another example\n",
    "sentence1 = \"canteen be a great place to catch up with friends and i have always loved spend time in a laboratories\"\n",
    "sentence2 = \"canteen is a great place to catch up with friends and i have always loved spending time in laboratories\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results for the second example\n",
    "print(\"\\nExample: \\n\")\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "print(\"\\n\")\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n",
    "\n",
    "\n",
    "# Sort moved words 2 by the original index for the second example\n",
    "sorted_moved_words2 = sorted(moved_words2, key=lambda x: x[1])\n",
    "# Create a dictionary with the word as the key and the index as the value\n",
    "moved_words2_dict = {word: index for word, index in sorted_moved_words2}\n",
    "\n",
    "# Output in JSON format for the second example\n",
    "moved_words2_json = json.dumps(moved_words2_dict, indent=4)\n",
    "print(\"Moved Words 2 (JSON) for the second example:\")\n",
    "print(moved_words2_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories be a spend\n",
      "Retained Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories\n",
      "Retained Words 1: [('canteen', 0), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17), ('a', 18), ('laboratories', 19)]\n",
      "Moved Words 1: [('be', 1), ('a', 2), ('spend', 15)]\n",
      "Modified Sentence 2: canteen laboratories is spending a great place to catch up with friends and i have always loved time in\n",
      "Retained Sentence 2: canteen laboratories\n",
      "Retained Words 2: [('canteen', 0), ('laboratories', 18)]\n",
      "Moved Words 2: [('is', 1), ('spending', 15), ('a', 2), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17)]\n",
      "Moved Words 2 (JSON):\n",
      "{\n",
      "    \"is\": 1,\n",
      "    \"a\": 2,\n",
      "    \"great\": 3,\n",
      "    \"place\": 4,\n",
      "    \"to\": 5,\n",
      "    \"catch\": 6,\n",
      "    \"up\": 7,\n",
      "    \"with\": 8,\n",
      "    \"friends\": 9,\n",
      "    \"and\": 10,\n",
      "    \"i\": 11,\n",
      "    \"have\": 12,\n",
      "    \"always\": 13,\n",
      "    \"loved\": 14,\n",
      "    \"spending\": 15,\n",
      "    \"time\": 16,\n",
      "    \"in\": 17\n",
      "}\n",
      "\n",
      "Second Example:\n",
      "Modified Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories be a spend\n",
      "Retained Sentence 1: canteen great place to catch up with friends and i have always loved time in a laboratories\n",
      "Retained Words 1: [('canteen', 0), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17), ('a', 18), ('laboratories', 19)]\n",
      "Moved Words 1: [('be', 1), ('a', 2), ('spend', 15)]\n",
      "Modified Sentence 2: canteen laboratories is spending a great place to catch up with friends and i have always loved time in\n",
      "Retained Sentence 2: canteen laboratories\n",
      "Retained Words 2: [('canteen', 0), ('laboratories', 18)]\n",
      "Moved Words 2: [('is', 1), ('spending', 15), ('a', 2), ('great', 3), ('place', 4), ('to', 5), ('catch', 6), ('up', 7), ('with', 8), ('friends', 9), ('and', 10), ('i', 11), ('have', 12), ('always', 13), ('loved', 14), ('time', 16), ('in', 17)]\n",
      "Moved Words 2 (JSON) for the second example:\n",
      "{\n",
      "    \"is\": 1,\n",
      "    \"a\": 2,\n",
      "    \"great\": 3,\n",
      "    \"place\": 4,\n",
      "    \"to\": 5,\n",
      "    \"catch\": 6,\n",
      "    \"up\": 7,\n",
      "    \"with\": 8,\n",
      "    \"friends\": 9,\n",
      "    \"and\": 10,\n",
      "    \"i\": 11,\n",
      "    \"have\": 12,\n",
      "    \"always\": 13,\n",
      "    \"loved\": 14,\n",
      "    \"spending\": 15,\n",
      "    \"time\": 16,\n",
      "    \"in\": 17\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def move_different_word_to_end(sentence1, sentence2):\n",
    "    def move_words_to_end(sentence_words, words_to_move):\n",
    "        retained_words = []\n",
    "        moved_words = []\n",
    "        words_to_move_count = Counter(words_to_move)\n",
    "        \n",
    "        for idx, word in enumerate(sentence_words):\n",
    "            if words_to_move_count[word] > 0:\n",
    "                moved_words.append((word, idx))\n",
    "                words_to_move_count[word] -= 1\n",
    "            else:\n",
    "                retained_words.append((word, idx))\n",
    "        \n",
    "        return retained_words, moved_words\n",
    "\n",
    "    # Remove punctuation using regex and convert sentences to lowercase\n",
    "    sentence1 = re.sub(r'[^\\w\\s]', '', sentence1).lower()\n",
    "    sentence2 = re.sub(r'[^\\w\\s]', '', sentence2).lower()\n",
    "\n",
    "    # Split sentences into words\n",
    "    words1 = sentence1.split()\n",
    "    words2 = sentence2.split()\n",
    "\n",
    "    # Identify unique words\n",
    "    counter1 = Counter(words1)\n",
    "    counter2 = Counter(words2)\n",
    "    unique_words1 = counter1 - counter2\n",
    "    unique_words2 = counter2 - counter1\n",
    "\n",
    "    # Move unique words to the end and get retained and moved words with their original indices\n",
    "    retained_words1, moved_words1 = move_words_to_end(words1, unique_words1)\n",
    "    retained_words2, moved_words2 = move_words_to_end(words2, unique_words2)\n",
    "\n",
    "    return retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "def update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2):\n",
    "    # Create a list to store words to move based on positional mismatch\n",
    "    moved_words2_part2 = []\n",
    "\n",
    "    # Track matched positions to handle duplicates correctly\n",
    "    matched_indices_retained1 = [False] * len(retained_words1)\n",
    "\n",
    "    # Find words in retained_words2 that do not match their position in retained_words1\n",
    "    for idx2, (word2, pos2) in enumerate(retained_words2):\n",
    "        found_match = False\n",
    "        for idx1, (word1, pos1) in enumerate(retained_words1):\n",
    "            if not matched_indices_retained1[idx1] and word2 == word1 and idx1 == idx2:\n",
    "                matched_indices_retained1[idx1] = True\n",
    "                found_match = True\n",
    "                break\n",
    "        if not found_match:\n",
    "            moved_words2_part2.append((word2, pos2))\n",
    "    \n",
    "    # Update moved_words2 with these additional words\n",
    "    moved_words2.extend(moved_words2_part2)\n",
    "    \n",
    "    # Filter retained_words2 to remove the words that have been moved\n",
    "    retained_words2 = [(word, idx) for word, idx in retained_words2 if (word, idx) not in moved_words2_part2]\n",
    "    \n",
    "    return retained_words2, moved_words2\n",
    "\n",
    "def get_final_sentences_and_words(sentence1, sentence2):\n",
    "    retained_words1, moved_words1, retained_words2, moved_words2 = move_different_word_to_end(sentence1, sentence2)\n",
    "\n",
    "    # Update moved_words2 based on position comparison\n",
    "    retained_words2, moved_words2 = update_moved_words_based_on_position(retained_words1, retained_words2, moved_words2)\n",
    "\n",
    "    # Form the final sentences\n",
    "    modified_sentence1 = \" \".join(word for word, _ in retained_words1 + moved_words1)\n",
    "    modified_sentence2 = \" \".join(word for word, _ in retained_words2 + moved_words2)\n",
    "    retained_sentence1 = \" \".join(word for word, _ in retained_words1)\n",
    "    retained_sentence2 = \" \".join(word for word, _ in retained_words2)\n",
    "\n",
    "    return modified_sentence1.strip(), modified_sentence2.strip(), retained_sentence1.strip(), retained_sentence2.strip(), retained_words1, moved_words1, retained_words2, moved_words2\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"Canteen be a great place to catch up with friends and I have always loved spend time in a laboratories.\"\n",
    "sentence2 = \"Canteen is a great place to catch up with friends and I have always loved spending time in laboratories.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n",
    "\n",
    "# Sort moved words 2 by the original index\n",
    "sorted_moved_words2 = sorted(moved_words2, key=lambda x: x[1])\n",
    "# Create a dictionary with the word as the key and the index as the value\n",
    "moved_words2_dict = {word: index for word, index in sorted_moved_words2}\n",
    "\n",
    "# Output in JSON format\n",
    "moved_words2_json = json.dumps(moved_words2_dict, indent=4)\n",
    "print(\"Moved Words 2 (JSON):\")\n",
    "print(moved_words2_json)\n",
    "\n",
    "# Test with another example\n",
    "sentence1 = \"Canteen be a great place to catch up with friends and I have always loved spend time in a laboratories.\"\n",
    "sentence2 = \"Canteen is a great place to catch up with friends and I have always loved spending time in laboratories.\"\n",
    "\n",
    "result1, result2, retained_sentence1, retained_sentence2, retained_words1, moved_words1, retained_words2, moved_words2 = get_final_sentences_and_words(sentence1, sentence2)\n",
    "\n",
    "# Print results for the second example\n",
    "print(\"\\nSecond Example:\")\n",
    "print(\"Modified Sentence 1:\", result1)\n",
    "print(\"Retained Sentence 1:\", retained_sentence1)\n",
    "print(\"Retained Words 1:\", retained_words1)\n",
    "print(\"Moved Words 1:\", moved_words1)\n",
    "\n",
    "print(\"Modified Sentence 2:\", result2)\n",
    "print(\"Retained Sentence 2:\", retained_sentence2)\n",
    "print(\"Retained Words 2:\", retained_words2)\n",
    "print(\"Moved Words 2:\", moved_words2)\n",
    "\n",
    "# Sort moved words 2 by the original index for the second example\n",
    "sorted_moved_words2 = sorted(moved_words2, key=lambda x: x[1])\n",
    "# Create a dictionary with the word as the key and the index as the value\n",
    "moved_words2_dict = {word: index for word, index in sorted_moved_words2}\n",
    "\n",
    "# Output in JSON format for the second example\n",
    "moved_words2_json = json.dumps(moved_words2_dict, indent=4)\n",
    "print(\"Moved Words 2 (JSON) for the second example:\")\n",
    "print(moved_words2_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"is\": 1,\n",
      "    \"the\": 2,\n",
      "    \"there\": 8,\n",
      "    \"are\": 9,\n",
      "    \"maan\": 10,\n",
      "    \"y\": 11,\n",
      "    \"spending\": 19,\n",
      "    \"manipal\": 23,\n",
      "    \"hospitals\": 24\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def remove_repeats(sentence):\n",
    "    # Patterns for two-word and three-word repeats\n",
    "    pattern_one_word = re.compile(r'\\b(\\w+)\\b\\s+\\1\\b')\n",
    "    pattern_two_words = re.compile(r'\\b(\\w+\\s+\\w+)\\b\\s+\\1\\b')\n",
    "    pattern_three_words = re.compile(r'\\b(\\w+\\s+\\w+\\s+\\w+)\\b\\s+\\1\\b')\n",
    "    \n",
    "    # Replace repeats with the first occurrence\n",
    "    while True:\n",
    "        new_sentence = sentence\n",
    "        new_sentence = pattern_one_word.sub(r'\\1', new_sentence)\n",
    "        new_sentence = pattern_two_words.sub(r'\\1', new_sentence)\n",
    "        new_sentence = pattern_three_words.sub(r'\\1', new_sentence)\n",
    "        if new_sentence == sentence:\n",
    "            break\n",
    "        sentence = new_sentence\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Example usage\n",
    "sentence1 = \"Canteen be a great place to catch up with friends, and I have always loved spend time in a. laboratories\"\n",
    "sentence2 = \"Canteen Canteen is the great place to catch up there are maan y with friends and I have always loved spending time in laboratories. manipal hospitals\"\n",
    "\n",
    "\n",
    "sentence1 = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence1)\n",
    "sentence1 = remove_repeats(sentence1)\n",
    "sentence2 = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", sentence2)\n",
    "sentence2 = remove_repeats(sentence2)\n",
    "\n",
    "def remove_repeated_words(sentence1, sentence2):\n",
    "    combined_sentence = sentence1 + \" \" + sentence2\n",
    "    words = combined_sentence.split()\n",
    "    word_count = {}\n",
    "    \n",
    "    # Count the occurrences of each word in the combined sentences\n",
    "    for word in words:\n",
    "        word_count[word] = word_count.get(word, 0) + 1\n",
    "    \n",
    "    # Collect unique words from each sentence\n",
    "    unique_words1 = [word for word in sentence1.split() if word_count[word] == 1]\n",
    "    unique_words2 = [word for word in sentence2.split() if word_count[word] == 1]\n",
    "    \n",
    "    return unique_words1, unique_words2\n",
    "\n",
    "def find_unique_words_with_indices(sentence1, sentence2):\n",
    "    # Remove repeated words from both sentences\n",
    "    unique_words1, unique_words2 = remove_repeated_words(sentence1, sentence2)\n",
    "    \n",
    "    # Create sets of unique words\n",
    "    set1 = set(unique_words1)\n",
    "    set2 = set(unique_words2)\n",
    "    \n",
    "    # Find words in sentence2 that are not in sentence1\n",
    "    difference = set2 - set1\n",
    "    \n",
    "    # Find indices of these words in sentence2\n",
    "    words_with_indices = {}\n",
    "    words2 = sentence2.split()\n",
    "    for index, word in enumerate(words2):\n",
    "        if word in difference:\n",
    "            words_with_indices[word] = index\n",
    "    \n",
    "    return words_with_indices\n",
    "\n",
    "result = find_unique_words_with_indices(sentence1, sentence2)\n",
    "result_json = json.dumps(result, indent=4)\n",
    "print(result_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        text has_non_english\n",
      "0      This is English text.             YES\n",
      "1               This has 中文.             YES\n",
      "2  This text is all English.             YES\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def has_non_english_word(text):\n",
    "  \"\"\"\n",
    "  Checks if a string contains characters outside the basic English alphabet.\n",
    "\n",
    "  Args:\n",
    "      text: The string to check.\n",
    "\n",
    "  Returns:\n",
    "      \"YES\" if the string contains non-English characters, \"NO\" otherwise.\n",
    "  \"\"\"\n",
    "  pattern = r\"[^\\s\\w\\-]\"  # Matches characters that are not whitespace, word characters, or hyphen\n",
    "  return \"YES\" if re.search(pattern, text) else \"NO\"\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'text': ['This is English text.', 'This has 中文.', 'This text is all English.']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "df['has_non_english'] = df['text'].apply(has_non_english_word)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
